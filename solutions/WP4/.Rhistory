# Chunk 1: setup
library(formatR)
library(scales)
library(tidyverse)
library(estimatr)
knitr::opts_chunk$set(tidy.opts = list(width.cutoff = 60), tidy = TRUE)
# Chunk 2
data <- tibble(
unit = 1:6,
Y = c(1,NA_real_, 1, 0,1,NA_real_),
R = c(1,0,1,1,1,0),
x1 = c(0,0,0,0,1,1),
x2 = c(3,7,9,5,4,3)
)
# Chunk 3
data %>%
select(Y)%>%
summarise(E_Y = mean(Y, na.rm = T))%>%
pull()
# Chunk 4
algo <- lm_robust(Y ~ x1 + x2, data = data)
mean(predict(algo, data))
# Chunk 5
set.seed(30)
N <- 2500
d4 <- tibble(
unit = 1:N,
salary = rnorm(N, mean = 1000, sd = 106)
)%>%
mutate(education_b = rnorm(N, 8, 1),
education_s = salary * 0.04,
education = rescale(education_b + education_s + runif(N, 0,1)),
D_score= 0.5*salary + 1.5*education + rnorm(N),
D_prob = rescale(D_score, to = c(0.05, .95)),
D = rbinom(N, 1, D_prob),
Y_base = rbeta(N, shape1 = 4, shape2 = 5)*100,
Y_eff = 20*D + 2*education + 0.1*salary  + Y_base + rnorm(N),
Y = rescale(Y_eff, to = c(5,80)))%>%
select(unit, salary, education, D, Y)
# Chunk 6
lm_robust(Y~D, data = d4)
# Chunk 8
pscore <- glm(D ~ salary + education, family = binomial(link = "logit"), data = d4)
# Chunk 10
d4 <- broom::augment(pscore, d4, type.predict = "response")%>%
rename(prop = .fitted)%>%
mutate(ipw = (D/prop) + ((1-D)/(1-prop)))%>%
# This line removes all the other augment junk we don't need for this problem
select(-contains("."))
head(d4)
# Chunk 12
coef_plot <- lm_robust(Y~D, data = d4, weights = ipw)%>%
tidy()%>%
# This is another way to filter out the intercept term
filter(!grepl("Int", term))%>%
ggplot(aes(x = estimate, y = term))+
geom_point()+
geom_errorbarh(aes(xmin = conf.low, xmax = conf.high))+
theme_bw()+
geom_vline(xintercept = 0)
coef_plot
